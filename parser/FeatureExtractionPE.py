import os
import pefile
import csv
import math

from multipledispatch import dispatch


# https://docs.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-_image_file_header
__FILE_HEADER = [
    'Machine',  # The architecture type of the computer.
    'NumberOfSections',  # The number of sections.
    'TimeDateStamp',  # The low 32 bits of the time stamp of the image.
    'PointerToSymbolTable',  # The offset of the symbol table, in bytes, or zero if no COFF symbol table exists.
    'NumberOfSymbols',  # The number of symbols in the symbol table.
    'SizeOfOptionalHeader',  # The size of the optional header, in bytes.
    'Characteristics'  # The characteristics of the image.
]

# https://docs.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-image_optional_header32
__OPTIONAL_HEADER = [
    'Magic',  # The state of the image file.
    'MajorLinkerVersion',  # The major version number of the linker.
    'MinorLinkerVersion',  # The minor version number of the linker.
    'SizeOfCode',
    # The size of the code section, in bytes, or the sum of all such sections if there are multiple code sections.
    'SizeOfInitializedData',
    # The size of the initialized data section, in bytes, or the sum of all such sections if there are multiple initialized data sections.
    'SizeOfUninitializedData',
    # The size of the uninitialized data section, in bytes, or the sum of all such sections if there are multiple uninitialized data sections.
    'AddressOfEntryPoint',  # A pointer to the entry point function, relative to the image base address.
    'BaseOfCode',  # A pointer to the beginning of the code section, relative to the image base.
    'BaseOfData',  # A pointer to the beginning of the data section, relative to the image base.
    'ImageBase',  # The preferred address of the first byte of the image when it is loaded in memory.
    'SectionAlignment',  # The alignment of sections loaded in memory, in bytes.
    'FileAlignment',  # The alignment of the raw data of sections in the image file, in bytes.
    'MajorOperatingSystemVersion',  # The major version number of the required operating system.
    'MinorOperatingSystemVersion',  # The minor version number of the required operating system.
    'MajorImageVersion',  # The major version number of the image.
    'MinorImageVersion',  # The minor version number of the image.
    'MajorSubsystemVersion',  # The major version number of the subsystem.
    'MinorSubsystemVersion',  # The minor version number of the subsystem.
    'Reserved1',  # (Win32VersionValue) This member is reserved and must be 0.
    'SizeOfImage',  # The size of the image, in bytes, including all headers.
    'SizeOfHeaders',
    # The combined size of the following items, rounded to a multiple of the value specified in the FileAlignment member.
    'CheckSum',  # The image file checksum.
    'Subsystem',  # The subsystem required to run this image.
    'DllCharacteristics',  # The DLL characteristics of the image.
    'SizeOfStackReserve',  # The number of bytes to reserve for the stack.
    'SizeOfStackCommit',  # The number of bytes to commit for the stack.
    'SizeOfHeapReserve',  # The number of bytes to commit for the local heap.
    'SizeOfHeapCommit',  # This member is obsolete.
    'LoaderFlags',  # The number of directory entries in the remainder of the optional header.
    'NumberOfRvaAndSizes'  # A pointer to the first IMAGE_DATA_DIRECTORY structure in the data directory.
]

__DIRECTORY_ENTRY_TYPES = {
    'IMAGE_DIRECTORY_ENTRY_EXPORT' : 0,
    'IMAGE_DIRECTORY_ENTRY_IMPORT' : 1,
    'IMAGE_DIRECTORY_ENTRY_RESOURCE' : 2,
    'IMAGE_DIRECTORY_ENTRY_EXCEPTION' : 3,
    'IMAGE_DIRECTORY_ENTRY_SECURITY' : 4,
    'IMAGE_DIRECTORY_ENTRY_BASERELOC' : 5,
    'IMAGE_DIRECTORY_ENTRY_DEBUG' : 6,
    'IMAGE_DIRECTORY_ENTRY_COPYRIGHT' : 7,
    'IMAGE_DIRECTORY_ENTRY_GLOBALPTR' : 8,
    'IMAGE_DIRECTORY_ENTRY_TLS' : 9,
    'IMAGE_DIRECTORY_ENTRY_LOAD_CONFIG' : 10,
    'IMAGE_DIRECTORY_ENTRY_BOUND_IMPORT' : 11,
    'IMAGE_DIRECTORY_ENTRY_IAT' : 12,
    'IMAGE_DIRECTORY_ENTRY_DELAY_IMPORT' : 13,
    'IMAGE_DIRECTORY_ENTRY_COM_DESCRIPTOR' : 14,
    'IMAGE_DIRECTORY_ENTRY_RESERVED' : 15
}

# https://docs.microsoft.com/en-us/windows/win32/debug/pe-format#section-table-section-headers
__SECTION_HEADER = [
    'VirtualSize',
    'VirtualAddress',
    'SizeOfRawData',
    'PointerToRawData',
    'PointerToRelocations',
    'PointerToLinenumbers',
    'NumberOfRelocations',
    'NumberOfLinenumbers',
    'Characteristics'
]

__RESOURCE_DIRECTORY_TABLE = [
    'Characteristics',
    'MajorVersion',
    'MinorVersion',
    'NumberOfIdEntries',
    'NumberOfNamedEntries',
    'TimeDateStamp'
]

__RESOURCE_TYPE = [
    'Cursors',
    'Bitmaps',
    'Icons',
    'Menus',
    'Dialogs',
    'Strings',
    'Fonts',
    'Group Cursors',
    'Group Icons'
]

# -----------------------------------------------------------------------------------------------------------------
# Extracting dll features from IAT (Import Address Table), it is referred in Optional Header Data Directories, has index 12.
# Located in .idata section


class DLLData:
    def __init__(self, dll_name):
        self.dll_name = dll_name
        self.count = 1
        self.function_data_list = list()

    def add_function(self, func_name):
        for func_data in self.function_data_list:
            if func_data.func_name == func_name:
                func_data.count += 1
                break
        else:
            self.function_data_list.append(FunctionData(func_name))


class FunctionData:
    def __init__(self, func_name):
        self.func_name = func_name
        self.count = 1


@dispatch(object,object,list)
def try_add_dll(entry, current_function, dll_list):
    if not current_function.name: return
    entry_dll_name = entry.dll.decode('utf-8').upper()
    function_name = current_function.name.decode('utf-8')

    for dll_data in dll_list:
        if dll_data.dll_name == entry_dll_name:
            dll_data.add_function(function_name)
            break
    else:
        new_data = DLLData(entry_dll_name)
        new_data.add_function(function_name)
        dll_list.append(new_data)


@dispatch(object,list)
def try_add_dll(entry, dll_list):
    entry_dll_name = entry.dll.decode('utf-8').upper()

    for dll_data in dll_list:
        if dll_data.dll_name == entry_dll_name:
            dll_data.count += 1
            break
    else:
        new_data = DLLData(entry_dll_name)
        dll_list.append(new_data)


def dll_list_to_csv(file_path, dll_list, *csv_header):
    with open(file_path, 'w',
              newline='')  as output_file:
        writer = csv.writer(output_file)
        writer.writerow(csv_header)
        for dll_data in dll_list:
            if not dll_data.function_data_list: writer.writerow((dll_data.dll_name, dll_data.count))
            else:
                for function_data in dll_data.function_data_list:
                    writer.writerow((dll_data.dll_name, function_data.func_name, function_data.count))


def extract_data(open_files_path, fullExtract):
    dll_list = []
    for filename in os.listdir(open_files_path):
        with open(os.path.join(open_files_path, filename), 'rb') as f:  # open in readonly mode
            file_data = f.read()
        try:
            pe = pefile.PE(data=file_data)
            if not hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                print('\t There are no imports for this PE-File')
                continue
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                if fullExtract:
                    for function in entry.imports:
                        try_add_dll(entry, function, dll_list)
                else:
                    try_add_dll(entry, dll_list)
        except pefile.PEFormatError as pefe:
            print('PEFormatError', pefe, os.path.basename(open_files_path))
        except Exception as e:
            print('Exception', e, os.path.basename(open_files_path))
    print(dll_list)
    return dll_list

# ---------------------------------------------------------------------------------------------------------------------


def extract_libraries(open_files_path, save_file_path):
    data = extract_data(open_files_path, True)
    dll_list_to_csv(save_file_path, data, 'DllName', 'FunctionName', 'Count')


def extract_dlls(open_files_path, save_file_path):
    data = extract_data(open_files_path, False)
    dll_list_to_csv(save_file_path, data, 'DllName', 'Count')


extract_libraries("D:/studying/Rhein-Waal Uni/1st semester/Project research A/benign files",
                  "D:/studying/Rhein-Waal Uni/1st semester/Project research A/tables/benign/libs_number_for_benignware.csv")

extract_dlls("D:/studying/Rhein-Waal Uni/1st semester/Project research A/benign files",
                  "D:/studying/Rhein-Waal Uni/1st semester/Project research A/tables/benign/dlls_number_for_benignware.csv")

# ---------------------------------------------------------------------------------------------------------------------


def result_list_to_csv(file_path, result_list, header_type):
    with open(file_path, 'w',
              newline='')  as output_file:
        writer = csv.writer(output_file)
        if header_type == '__FILE_HEADER':
            writer.writerow(__FILE_HEADER)
            writer.writerows(result_list)
        if header_type == '__OPTIONAL_HEADER':
            writer.writerow(__OPTIONAL_HEADER)
            writer.writerows(result_list)
        if header_type == '_OPTIONAL_HEADER_DATA_DIRECTORY':
            writer.writerow(create_csv_table_head(header_type))
            unpack_dict(result_list,writer)
        if header_type == '__SECTION_HEADER':
            writer.writerow(create_csv_table_head(header_type))
            writer.writerows(result_list)
        if header_type == '__DIRECTORY_ENTRY_RESOURCE':
            writer.writerow(__RESOURCE_TYPE)
            unpack_dict(result_list,writer)


def unpack_dict(result_list, writer):
    for member in result_list:
        for features_dict in member:
            writer.writerow(features_dict.values())


def create_csv_table_head(header_type):
    csv_head_list = list()
    if header_type == '__SECTION_HEADER':
        for section_name in ['text', 'data', 'resource']:
            for member_name in __SECTION_HEADER:
                csv_head_list.append(f'{section_name}:{member_name}')
            csv_head_list.append(f'{section_name}:entropy')
        return csv_head_list

    if header_type == '_OPTIONAL_HEADER_DATA_DIRECTORY':
        for key in __DIRECTORY_ENTRY_TYPES.keys():
            csv_head_list.append(f'{key}:VirtualAddress')
            csv_head_list.append(f'{key}:Size')
        return csv_head_list


def process_features(pe, result_list, header_type):
    file_features_list = list()
    result_list.append(file_features_list)

    # Feature From COFF file header
    if header_type == '__FILE_HEADER':
        for member in __FILE_HEADER:
            file_features_list.append(getattr(pe.FILE_HEADER, member, '-'))
    # Feature From Optional header: standard fields and Windows specific fields
    if header_type == '__OPTIONAL_HEADER':
        for member in __OPTIONAL_HEADER:
            file_features_list.append(getattr(pe.OPTIONAL_HEADER, member, '-'))
    # Feature From Optional header: data directories
    if header_type == '_OPTIONAL_HEADER_DATA_DIRECTORY':
        process_data_directory(pe,file_features_list)
    # Feature From Section headers
    if header_type == '__SECTION_HEADER':
        process_sections(pe, file_features_list)
    # Feature From Resource directory table & resources
    if header_type == '__DIRECTORY_ENTRY_RESOURCE':
        process_resource_section(pe, file_features_list)


def process_resource_section(pe, file_features_list):
    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):
        resources = dict()
        for resource_type in __RESOURCE_TYPE:
            resources[resource_type] = 0
        for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:
            # Cursors
            if resource_type.struct.Id == 1:
                resources['Cursors'] += len(resource_type.directory.entries)
            # Bitmaps
            elif resource_type.struct.Id == 2:
                resources['Bitmaps'] += len(resource_type.directory.entries)
            # Icons
            elif resource_type.struct.Id == 3:
                resources['Icons'] += len(resource_type.directory.entries)
            # Menus
            elif resource_type.struct.Id == 4:
                resources['Menus'] += len(resource_type.directory.entries)
            # Dialogs
            elif resource_type.struct.Id == 5:
                resources['Dialogs'] += len(resource_type.directory.entries)
            # Strings
            elif resource_type.struct.Id == 6:
                resources['Strings'] += len(resource_type.directory.entries)
            # Fonts
            elif resource_type.struct.Id == 8:
                resources['Fonts'] += len(resource_type.directory.entries)
            # Group Cursors
            elif resource_type.struct.Id == 12:
                resources['Group Cursors'] += len(resource_type.directory.entries)
            # Group Icons
            elif resource_type.struct.Id == 14:
                resources['Group Icons'] += len(resource_type.directory.entries)
        file_features_list.append(resources)


def process_data_directory(pe, file_features_list):
    directories = dict()
    for key in __DIRECTORY_ENTRY_TYPES.keys():
        directories[f'{key}:VirtualAddress'] = '-'
        directories[f'{key}:Size'] = '-'
    for structure in pe.OPTIONAL_HEADER.DATA_DIRECTORY:
        directories[f'{structure.name}:VirtualAddress'] = structure.VirtualAddress
        directories[f'{structure.name}:Size'] = structure.Size
    file_features_list.append(directories)


# get_entropy - returns entropy of some data - taken from PE file
def get_entropy(data):
    """Calculate the entropy of a chunk of data."""

    if not data:
        return 0

    entropy = 0
    for x in range(256):
        p_x = float(data.count(bytes(x)))/len(data)
        if p_x > 0:
            entropy += - p_x*math.log(p_x, 2)

    return entropy


def pre_process_section(section_name, pe, file_features_list):
    has_no_current_section = True
    for section in pe.sections:
        if not (section.Name == section_name): continue
        for member in __SECTION_HEADER:
            file_features_list.append(getattr(section, member, '-'))
        file_features_list.append(get_entropy(section.get_data()))
        has_no_current_section = False

    # fill current section data with "-"
    if has_no_current_section:
        for i in range(1, 11):
            file_features_list.append(str('-'))


def process_sections(pe, file_features_list):

    pre_process_section(b'.text\x00\x00\x00', pe, file_features_list)
    pre_process_section(b'.data\x00\x00\x00', pe, file_features_list)
    pre_process_section(b'.rsrc\x00\x00\x00', pe, file_features_list)

    # n is a number of columns in that table (csv file)
    n = 30
    if len(file_features_list) > n:
        # add 1st n attributes to the list
        tmp = file_features_list[:n]
        file_features_list.clear()
        for number in tmp:
            file_features_list.append(number)


def extract_features(open_files_path, save_file_path, header_type):
    result_list = list()
    for filename in os.listdir(open_files_path):
        with open(os.path.join(open_files_path, filename), 'rb') as f:  # open in readonly mode
            file_data = f.read()
        try:
            pe = pefile.PE(data=file_data)
            process_features(pe, result_list, header_type)
        except pefile.PEFormatError as pefe:
            print('PEFormatError', pefe, os.path.basename(open_files_path))
        except Exception as e:
            print('Exception', e, os.path.basename(open_files_path))
    result_list_to_csv(save_file_path, result_list, header_type)

# ---------------------------------------------------------------------------------------------------------------------


# Feature From COFF file header
def extract_coff_header_features(open_files_path, save_file_path):
    extract_features(open_files_path, save_file_path, '__FILE_HEADER')


# Feature From Optional header: standard fields and Windows specific fields
def extract_optional_header_features(open_files_path, save_file_path):
    extract_features(open_files_path, save_file_path, '__OPTIONAL_HEADER')


# Feature From Optional header: data directories
def extract_optional_header_data_directory(open_files_path, save_file_path):
    extract_features(open_files_path, save_file_path, '_OPTIONAL_HEADER_DATA_DIRECTORY')


# Feature From Section headers
def extract_section_header_data_features(open_files_path, save_file_path):
    extract_features(open_files_path, save_file_path, '__SECTION_HEADER')

# Feature From Resource directory table & resources
def extract_resources(open_files_path, save_file_path):
    extract_features(open_files_path, save_file_path, '__DIRECTORY_ENTRY_RESOURCE')


# extract_coff_header_features("D:/studying/Rhein-Waal Uni/1st semester/Project research A/benign files",
#                          "D:/studying/Rhein-Waal Uni/1st semester/Project research A/tables/benign/coff_header_feaures_for_benignware.csv")
#
# extract_optional_header_features("D:/studying/Rhein-Waal Uni/1st semester/Project research A/benign files",
#                              "D:/studying/Rhein-Waal Uni/1st semester/Project research A/tables/benign/optional_header_feaures_for_benignware.csv")

# extract_optional_header_data_directory("D:/studying/Rhein-Waal Uni/1st semester/Project research A/benign files",
#                                         "D:/studying/Rhein-Waal Uni/1st semester/Project research A/tables/benign/optional_header_data_directory__for_benignware.csv")
#
# extract_section_header_data_features("D:/studying/Rhein-Waal Uni/1st semester/Project research A/benign files",
#                                "D:/studying/Rhein-Waal Uni/1st semester/Project research A/tables/benign/section_header_data_features__for_benignware.csv")

# extract_resources("D:/studying/Rhein-Waal Uni/1st semester/Project research A/benign files",
#                   "D:/studying/Rhein-Waal Uni/1st semester/Project research A/tables/resources_section_for_benignware.csv")





